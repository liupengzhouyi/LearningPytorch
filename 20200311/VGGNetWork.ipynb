{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGGNetWork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWx2hAfZ0UiuCEEGgCYeDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liupengzhouyi/LearningPytorch/blob/master/20200311/VGGNetWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4q3dLYuEVED",
        "colab_type": "text"
      },
      "source": [
        "# VGG NetWork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFgHeRpiEZfo",
        "colab_type": "text"
      },
      "source": [
        "## import package\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL5sYFZDEbYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpvWgdX0Ei8m",
        "colab_type": "text"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDvIyhhzEmcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomGrayscale(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform1 = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlVt-k1uEvuU",
        "colab_type": "text"
      },
      "source": [
        "## Create DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgqRGS7ZEymZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp1O3ydxFBF-",
        "colab_type": "text"
      },
      "source": [
        "## Create classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZlevLiZFDl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-SrAt3-FGkr",
        "colab_type": "text"
      },
      "source": [
        "## Create VGG Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJoM9Ak0FKnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,  out_channels=64, kernel_size=3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64,  out_channels=128, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding=1)\n",
        "        self.conv7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1,padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv8 = nn.Conv2d(in_channels=128,  out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv9 = nn.Conv2d(in_channels=256,  out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        self.fc14 = nn.Linear(512*4*4,1024)\n",
        "        self.drop1 = nn.Dropout2d()\n",
        "        self.fc15 = nn.Linear(1024,1024)\n",
        "        self.drop2 = nn.Dropout2d()\n",
        "        self.fc16 = nn.Linear(1024,10)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.conv11(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.pool5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "        \n",
        "        x = x.view(-1,512*4*4)\n",
        "        x = F.relu(self.fc14(x))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.fc15(x))\n",
        "        x = self.drop2(x)\n",
        "        x = self.fc16(x)\n",
        "        return x\n",
        "\n",
        "    def train_sgd(self,device):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        path = 'weights.tar'\n",
        "        initepoch = 0\n",
        "\n",
        "        if os.path.exists(path) is not True:\n",
        "            loss = nn.CrossEntropyLoss()\n",
        "\n",
        "        else:\n",
        "            checkpoint = torch.load(path)\n",
        "            self.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            initepoch = checkpoint['epoch']\n",
        "            loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for epoch in range(initepoch,100):  # loop over the dataset multiple times\n",
        "            timestart = time.time()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device),labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = self(inputs)\n",
        "                l = loss(outputs, labels)\n",
        "                l.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += l.item()\n",
        "                # print(\"i \",i)\n",
        "                if i % 500 == 499:  # print every 500 mini-batches\n",
        "                    print('[%d, %5d] loss: %.4f' % (epoch, i, running_loss / 500))\n",
        "                    running_loss = 0.0\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total, 100.0 * correct / total))\n",
        "                    total = 0\n",
        "                    correct = 0\n",
        "                    torch.save({'epoch':epoch,\n",
        "                                'model_state_dict':net.state_dict(),\n",
        "                                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                                'loss':loss\n",
        "                                },path)\n",
        "\n",
        "            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\n",
        "\n",
        "        print('Finished Training')\n",
        "\n",
        "    def test(self,device):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the network on the 10000 test images: %.3f %%' % (\n",
        "                100.0 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sbY42AxHHb_",
        "colab_type": "text"
      },
      "source": [
        "## setting device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoGI1y7lHPbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaVdeocbHU4T",
        "colab_type": "text"
      },
      "source": [
        "## Intantiation Model and upload model to gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBIdWIl_HURx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jprfAWC9HigU",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MF1hdpBHjhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.train_sgd(device)\n",
        "net.test(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}